---
title: "A/B testing, Bayes style"
output:  html_document
---

```{r, echo=FALSE}
source('bayesianABTesting.R')
#theme_set(theme_minimal(12))
```

##But why?
So that you understand your test results correctly, including the uncertainty in them, without the p-value hassle.

###Also:

Gentle introduction to Bayesian methods.

###After this
You understand the results of Bayesin analysis, and are familiar with terms such as _posterior_,  _prior_, and _statistical model_.

***

##Our case

Reaktor website has a one-click purchase of a fixed-price-scope schedule-team agile software project, or whatever. More to the point, there are _two variants of the button_. Which is better? How much?

**What do we measure**? 

Visits on the page and button clicks.

Below are some simulated data, with pre-set click rates. Those are the underlying rates that we do not know in the measurement situation, and which we are after. Per day, we have on average 1500 visits on the page, of which 20% see the option __B__, for a total of six days.

Note that if you re-knit this document from the R Markdown file, data is re-generated and the results will change. How clear the difference between __A__ and __B__ looks like, from the raw click rates, _varies by run_. _That's also how it is in real life!_ Our goal is to get beyond that variation to get an idea of how things are in reality. 

Reality here refers to the pre-set click rates. In practice we also have pre-set click rates, but they are set by  nature. We do not observe them directly. We observe only data.

```{r}
rate.A <- 0.052
rate.B <- 0.068

example <- click.data(rate.A, rate.B, mean.visits=1500, test.group=0.2, days=6)

print(example)
```

So this is the (simulated) setup, and the data above is all we know from measurements. 

---

That's how the data looks like as plots:

```{r}
example.plots <- click.plots(example)
print(example.plots$histograms)
print(example.plots$rates)
```

---

##Let's mathematics 

(If you want results without too much understanding, skip to the practical section below.)

_What do we want to know?_ The pre-defined click rates, set by nature,  $\theta_A$ and $\theta_B$ that the visitor buys a project when shown either button __A__ or __B__. In our example where we played nature and generated the data, the rates were __rate.A__ and __rate.B__.

_What do we have?_ Click and visit counts, $k$ and $N$.

---

###A statistical model

Think how the data is generated.

If the click rate or the change to click is $\theta$ per visit, the probability to get a click/no-click sequence 00101 is

$$(1-\theta)\,(1-\theta)\,\theta\,(1-\theta)\,\theta\;.$$

For a _single_ sequence of $k$ clicks and $N-k$ non-clicks, the probability is

$$\theta^k\, (1-\theta)^{N-k}\;.$$

The probability to get _any_ sequence with $k$ clicks and $N-k$  non-cliks is

$$\text{(Number of sequences with $k$ clicks and $N-k$ non-clicks)} \times \theta^k\, (1-\theta)^{N-k}\;.$$

That number of sequences does not depend on click rate, so we don't need to care about it really. But for completeness, it is $N!/(k!(N-k)!)$. So the probability to get a data, or in other words any sequence, with $k$ clicks is

$$p(k, N|\theta) = \frac{N!}{k!(N-k)!} \theta^k\, (1-\theta)^{N-k}\, \propto\, \theta^k\, (1-\theta)^{N-k}\;.$$

That "$\propto$" is "proportional to", and just means that we eventually can skip the constant (as we will see). (Also note that the probability is in no way absolute, the same in all settings, but conditional on the click rate $\theta$.)

Okey, so we know the probability of data of length $N$ with $k$ clicks, given click rate $\theta$. Sadly, this is the wrong way, as it always tends to be statistics.

Now we have the probability of data we have seen, given reality. But that reality is unknown! What we want is the probability of reality given the data se have.

---

###Enter Bayes

Think about the conditional probability for a while. What is the probability to see a full moon tonight? It is, to a first approximation, the probability that it is full-moon time in general, times the probability that you see the moon, if it is there:

$$p(\text{full moon & seen}) = p(\text{seen}\, |\, \text{full moon}) \times p(\text{full moon})$$. 

You can invent better examples, but the general idea is that for two events $X$ and $Y$, the probability of both occurring is the probability that the first ($X$) occurs, times the probability that $Y$ occurs given $X$, or vice versa.

$$p(X, Y) = p(X | Y)\, p(Y) = p(Y | X)\, p(X)\;.$$

This is quite self-evident, but powerful when applied in a more abstract context. What is the probability of seeing data $D$ and being in world $W$?

$$p(D, W) = p(D | W)\, p(W) = p(W | D)\, p(D)\;.$$

In other words, 

$$
p(W | D) = \frac{p(D | W)\, p(W)}{p(D)}\;.
$$

This is quite remarkable, called _the Bayes rule_. It says that if you have _a model_ that gives the probability of data $D$, given a state of the world $W$, you can get the probability of _world itself, given data_, by simple multiplication (or so it seems).

How does this apply to our click rates? Our data $D$ are the observed $k, N$, and our world is described by one simple probability, the click rate $\theta$. Applying Bayes rule, we have
$$
p(\theta | k, N) = \frac{p(k, N\, | \, \theta)\, p(\theta)}{p(k, N)} 
= \frac{N!}{k!(N-k)!} \theta^k\, (1-\theta)^{N-k}\; \frac{p(\theta)}{p(k, N)}\;.
$$

At this point it helps a lot to note that in a practical setting the data $N$ and $k$ are what they are, they do not change. If we are after $p(\theta\,|\,N, k)$, and especially willing to mainly know how likely different click rates $\theta$ are _compared to each other_, we can drop all constant multiplies. That is, we can drop all multipliers where $\theta$ does not appear. This includes the weird "probability of data" $p(k, N)$ which is constant anyway, as well as the binomial coefficients $N!/(k!(N-k)!)$ originally arising from the number of possible click sequences. We are then left with just

$$ 
p(\theta\, |\, k, N) \propto \theta^k\, (1-\theta)^{N-k}\;p(\theta)\;.
$$
The constant left out form our "propto" or " $\propto$ can be later determined, if needed, from the fact that the sum or integral of the probabilities need to be one: $\int p(\theta\,|\,k, N)\;d\theta$ = 1. (If you google for "beta distribution", you'll find the constant.)

The probability distribution $p(\theta\, |\, k, N)$ is called _the posterior_, because it carries our information of the world _after_ the data.

There is one more thing: $p(\theta)$, or the probability of various click rates before any data. WTF is that? It is my prejudice or domain knowledge about how the click rates in general are, prior to seeing data. If I have no idea, a decent alternative is to set $p(\theta)=\text{const.}$, or that all click rates are equally good guesses. ($p(\theta)$ is called _prior_, and we'll come back to it later.)

---

Ok, back to reality. :) 
How do $p(\theta\,|\,N, k)$ look like in practice, for the counts of clicks and visits we have? Below are plots for daily click rates. There is now a separate click rate $\theta$ behind the observed clicks of each day, and for variants __A__ and __B__ separately. That is, 12 different $\theta$'s. (We will stick with two later.) Dashed lines are the true values, that we happen to (exceptionally) know because we're simulating nature here...


```{r}
example.posterior <- abtest.posteriorplot(example)
# quartz(width=14, height=6)
print(example.posterior$plot
      + geom_vline(xintercept=rate.A, linetype='dashed', colour="dodgerblue4")
      + geom_vline(xintercept=rate.B, linetype='dashed', colour="goldenrod2")
      + scale_color_manual(values=c("dodgerblue4", "goldenrod2"))
      + scale_y_continuous(breaks=NULL)
      + scale_x_continuous(breaks=c(.02, .05, .1))
      + xlab("theta") + ylab("probability (density)"))

```

## Getting practical

Happened so far: Given number of clicks $k$, and the total number of visits, $N$, we were able to compute the _probability distribution_ of the underlying true click rate, given the data:
$$
p(\theta\, |\, k, N) \propto \theta^k\, (1-\theta)^{N-k}\.
$$

Probability distributions of things in the world are called _posteriors_ in general, because they come after data.  This particular posterior is of the mathematical form called _Beta distribution_. Not all probabilities of unknown things in the world are Beta distributed. Here it arises because of our model happens to be such. 

### Simulating from a posterior

If you google for Beta distribution, you may stumble functions that _generate "random variates" that are Beta distributed_. A random variate here is a fancy word for a number. :) In R the relevant function is __rbeta()__. 

So you have 212 visits in total, and 13 clicks, and do want to see possible values for the true click rate?
```{r}
click.rate.samples <- rbeta(10000, 13+1, 212-13+1)
qplot(click.rate.samples) + geom_histogram() + xlim(0, .2)
```

So that was quite easy. :) Those $+1$'s come from the $p(\theta)$ of the previous section, and they basically say "Prior to data, I have no idea what the click rate is, or even if I have, I don't want to tell.". 

Compare to the Beta distribution obtained with our function
````{r}
betaplots(mean=13/212, sample.size=212) + xlim(0, .2)
```

In practice, managing our result $p(\theta\,|\,N, k)$ is often easier if we take those random samples from __rbeta()__, instead of trying to track the analytical distribution. There are analogous functions in Python or Javascript for example. 

For many simple models, the posteriorcan be written as a formula, or "in analytical form" as statisticians say. If there are a lot of data, it can often be approximated by the normal distribution even if the model is not so simple. Then there are models for which we cannot have a analytic posterior, not even a good approximation. But maybe surprisingly, we can often still get samples from the posterior! This may require heavy computation.

Here we stick with our particular simple model, and __rbeta()__ is sufficient.


### How about the comparison of A and B?



### The "I have no prior idea thing"... what if you have?

Conjugate priors

### What happens to the posterior, when data increases?


### What is the classic A/B testing in this context? p-values?

### Extensions

### What you need to remember




```
Matemaattisesti: mik?? on todenn??k??isyys p ostaa varianteilla
Oikea kysymys : mik?? on p?
Malli: Binomiaali jakauma
kuinka monta konversiota N n??yt??ll???
Malli sille miten ajatellaan datan generoituneen
v????rinp??in (data ehdolla malli)
Bayesin kaava (johto, saa olla ym??rt??m??tt??)
Priori vakioksi, palataan my??h
Posteriori plotteja -> kaikki ymm??rt???? mik?? on posteriori. 
todenn??k??isyysjakaumat mitta meid??n ep??varmuudelle
Posteriorista voidaan laskea hakutut asiat
kuinka paljon toinen on parempi (keskinm????rin), kuinka varmaa on ett?? on parempi
Priori
Katotaa Bayesin kaavaa
prioriin pakko laittaa jotain
priori on AINA, my??s frekventisteill??, vakkei ne aina my??nn??
Meid??n ennakkoluulo asiasta
Luonnollista laittaa tasainen -> ei tiedet?? mit????n
toinen tapa, laitetaan matemaattisesti kivan muotoinen funktio -> funktio ei muuta muotoa kun lis??t????n likelihood
konjugaatti priori
t??ss?? Beta
Esimerkki, tehd????n sama analyysi Beta priorilla
Eri countit nyt
Poll: mik?? on konversio todenn??k??isyys?
Poll: paljonko haluat dataa ett?? hylk????t ennakkoluulon?
Betan parametrit tulee t??st?? (selitet????nk???)
Betan keskiarvo ja hajonta (Poll: onko informatiivista?)
Uusia posterioiri plotteja

Huomaa:
Laskut n??in helppoja vain t??ss?? tapauksessa, hyvin harvoin -> Syy miksi Bayes ei ole yleistynyt
Nyky????n tietskarit tekee simulaatioilla, ei en???? niin vaikeeta

Extroja:
Frekventistisi?? tuloksia, milt?? n??ytt????? N??m??kin on oikein, eri tapa esitt????
Monta ryhm???? (A/B ei viittaa ryhmien m????r????n vaan outcomien m????r????n) monta treatment
kovariaatit -> probabilistig programming, ratkaisee ongelman todenn??k??isyyden k????n??st?? 
Testiryhmien tekeminen ja kontrollointi T??RKE????.
Menee helposti pieleen.
Tapauskohtaista.
ajalliset vaikutukset
```